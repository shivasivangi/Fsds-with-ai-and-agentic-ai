{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "586cb9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5f983e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aff9309d",
   "metadata": {},
   "outputs": [
    {
     "ename": "DefaultCredentialsError",
     "evalue": "Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDefaultCredentialsError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m init_chat_model\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m model = \u001b[43minit_chat_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemini-2.5-flash\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgoogle_genai\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SHIVA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain\\chat_models\\base.py:311\u001b[39m, in \u001b[36minit_chat_model\u001b[39m\u001b[34m(model, model_provider, configurable_fields, config_prefix, **kwargs)\u001b[39m\n\u001b[32m    303\u001b[39m     warnings.warn(\n\u001b[32m    304\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_prefix\u001b[38;5;132;01m=}\u001b[39;00m\u001b[33m has been set but no fields are configurable. Set \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    305\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`configurable_fields=(...)` to specify the model params that are \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    306\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mconfigurable.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    307\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    308\u001b[39m     )\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m configurable_fields:\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_init_chat_model_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model:\n\u001b[32m    317\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m] = model\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SHIVA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain\\chat_models\\base.py:368\u001b[39m, in \u001b[36m_init_chat_model_helper\u001b[39m\u001b[34m(model, model_provider, **kwargs)\u001b[39m\n\u001b[32m    365\u001b[39m     _check_pkg(\u001b[33m\"\u001b[39m\u001b[33mlangchain_google_genai\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    366\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_google_genai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGoogleGenerativeAI\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mChatGoogleGenerativeAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_provider == \u001b[33m\"\u001b[39m\u001b[33mfireworks\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    370\u001b[39m     _check_pkg(\u001b[33m\"\u001b[39m\u001b[33mlangchain_fireworks\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SHIVA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:1854\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m   1847\u001b[39m         suggestion = (\n\u001b[32m   1848\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Did you mean: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuggestions[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m?\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m suggestions \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1849\u001b[39m         )\n\u001b[32m   1850\u001b[39m         logger.warning(\n\u001b[32m   1851\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected argument \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1852\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mprovided to ChatGoogleGenerativeAI.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuggestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1853\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1854\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SHIVA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\load\\serializable.py:116\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    115\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419  # Intentional blank docstring\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SHIVA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:1921\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.validate_environment\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1918\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.base_url \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mapi_endpoint\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m client_options:\n\u001b[32m   1919\u001b[39m     client_options = {**client_options, \u001b[33m\"\u001b[39m\u001b[33mapi_endpoint\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.base_url}\n\u001b[32m-> \u001b[39m\u001b[32m1921\u001b[39m \u001b[38;5;28mself\u001b[39m.client = \u001b[43mgenaix\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild_generative_service\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1922\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1923\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgoogle_api_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1924\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1927\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1928\u001b[39m \u001b[38;5;28mself\u001b[39m.async_client_running = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1929\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SHIVA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_google_genai\\_genai_extension.py:286\u001b[39m, in \u001b[36mbuild_generative_service\u001b[39m\u001b[34m(credentials, api_key, client_options, client_info, transport)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_generative_service\u001b[39m(\n\u001b[32m    273\u001b[39m     credentials: Optional[credentials.Credentials] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    274\u001b[39m     api_key: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    277\u001b[39m     transport: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    278\u001b[39m ) -> v1betaGenerativeServiceClient:\n\u001b[32m    279\u001b[39m     config = _prepare_config(\n\u001b[32m    280\u001b[39m         credentials=credentials,\n\u001b[32m    281\u001b[39m         api_key=api_key,\n\u001b[32m   (...)\u001b[39m\u001b[32m    284\u001b[39m         client_info=client_info,\n\u001b[32m    285\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mv1betaGenerativeServiceClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SHIVA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:698\u001b[39m, in \u001b[36mGenerativeServiceClient.__init__\u001b[39m\u001b[34m(self, credentials, transport, client_options, client_info)\u001b[39m\n\u001b[32m    689\u001b[39m     transport_init: Union[\n\u001b[32m    690\u001b[39m         Type[GenerativeServiceTransport],\n\u001b[32m    691\u001b[39m         Callable[..., GenerativeServiceTransport],\n\u001b[32m   (...)\u001b[39m\u001b[32m    695\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m cast(Callable[..., GenerativeServiceTransport], transport)\n\u001b[32m    696\u001b[39m     )\n\u001b[32m    697\u001b[39m     \u001b[38;5;66;03m# initialize with the provided callable or the passed in class\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m698\u001b[39m     \u001b[38;5;28mself\u001b[39m._transport = \u001b[43mtransport_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_endpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient_cert_source_for_mtls\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_cert_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m        \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33masync\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m._transport):\n\u001b[32m    711\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m CLIENT_LOGGING_SUPPORTED \u001b[38;5;129;01mand\u001b[39;00m _LOGGER.isEnabledFor(\n\u001b[32m    712\u001b[39m         std_logging.DEBUG\n\u001b[32m    713\u001b[39m     ):  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SHIVA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\transports\\grpc.py:235\u001b[39m, in \u001b[36mGenerativeServiceGrpcTransport.__init__\u001b[39m\u001b[34m(self, host, credentials, credentials_file, scopes, channel, api_mtls_endpoint, client_cert_source, ssl_channel_credentials, client_cert_source_for_mtls, quota_project_id, client_info, always_use_jwt_access, api_audience)\u001b[39m\n\u001b[32m    230\u001b[39m             \u001b[38;5;28mself\u001b[39m._ssl_channel_credentials = grpc.ssl_channel_credentials(\n\u001b[32m    231\u001b[39m                 certificate_chain=cert, private_key=key\n\u001b[32m    232\u001b[39m             )\n\u001b[32m    234\u001b[39m \u001b[38;5;66;03m# The base transport sets the host, credentials and scopes\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m=\u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._grpc_channel:\n\u001b[32m    247\u001b[39m     \u001b[38;5;66;03m# initialize with the provided callable or the default channel\u001b[39;00m\n\u001b[32m    248\u001b[39m     channel_init = channel \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).create_channel\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SHIVA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\transports\\base.py:105\u001b[39m, in \u001b[36mGenerativeServiceTransport.__init__\u001b[39m\u001b[34m(self, host, credentials, credentials_file, scopes, quota_project_id, client_info, always_use_jwt_access, api_audience, **kwargs)\u001b[39m\n\u001b[32m    101\u001b[39m     credentials, _ = google.auth.load_credentials_from_file(\n\u001b[32m    102\u001b[39m         credentials_file, **scopes_kwargs, quota_project_id=quota_project_id\n\u001b[32m    103\u001b[39m     )\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m credentials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._ignore_credentials:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     credentials, _ = \u001b[43mgoogle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mscopes_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquota_project_id\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m     \u001b[38;5;66;03m# Don't apply audience if the credentials file passed from user.\u001b[39;00m\n\u001b[32m    109\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(credentials, \u001b[33m\"\u001b[39m\u001b[33mwith_gdch_audience\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SHIVA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\auth\\_default.py:739\u001b[39m, in \u001b[36mdefault\u001b[39m\u001b[34m(scopes, request, quota_project_id, default_scopes)\u001b[39m\n\u001b[32m    731\u001b[39m             _LOGGER.warning(\n\u001b[32m    732\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mNo project ID could be determined. Consider running \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    733\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m`gcloud config set project` or setting the \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    734\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33menvironment variable\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    735\u001b[39m                 environment_vars.PROJECT,\n\u001b[32m    736\u001b[39m             )\n\u001b[32m    737\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[32m--> \u001b[39m\u001b[32m739\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[31mDefaultCredentialsError\u001b[39m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information."
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4091ed63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='That\\'s a fantastic request! It highlights the overlapping and evolving nature of these terms.\\n\\nHere\\'s a comprehensive Table of Contents designed to differentiate and explain the relationships between Artificial Intelligence, Machine Learning, Generative AI, LLM Models, Prompt Engineering, and to address the term \"MCP\" in context.\\n\\n---\\n\\n**Table of Contents: Navigating the AI Landscape – Distinctions and Relationships**\\n\\n**I. Introduction to the AI Ecosystem**\\n    A. The Rapid Evolution of AI Terminology\\n    B. Purpose of This Guide: Clarifying Key Concepts\\n    C. The Hierarchical Nature of AI Sub-fields\\n\\n**II. Core Concepts & Definitions**\\n    A. **Artificial Intelligence (AI)**\\n        1.  Definition: The Broad Field of Simulating Human Intelligence\\n        2.  Goals & Capabilities: Problem-Solving, Learning, Perception, Reasoning\\n        3.  Historical Context & Different AI Paradigms (Symbolic AI, Connectionism)\\n        4.  Examples: Expert Systems, Robotics, Natural Language Processing (NLP), Computer Vision\\n    B. **Machine Learning (ML)**\\n        1.  Definition: A Subset of AI Focused on Learning from Data\\n        2.  Methodology: Algorithms, Data Training, Pattern Recognition\\n        3.  Types of ML: Supervised, Unsupervised, Reinforcement Learning\\n        4.  Applications: Recommendation Systems, Spam Detection, Predictive Analytics\\n    C. **Generative AI (GenAI)**\\n        1.  Definition: A Specialized Branch of ML Focused on Creating New Content\\n        2.  Key Characteristic: Generating Novel Data (Text, Images, Audio, Video, Code)\\n        3.  Underlying Technologies: Generative Adversarial Networks (GANs), Transformers, Variational Autoencoders (VAEs)\\n        4.  Impact & Capabilities: Content Creation, Design, Data Augmentation\\n    D. **Large Language Models (LLM Models)**\\n        1.  Definition: A Specific Type of Generative AI Model Optimized for Language Tasks\\n        2.  Architecture: Transformer-based Networks with Billions of Parameters\\n        3.  Training Data: Vast Corpora of Text and Code\\n        4.  Core Capabilities: Text Generation, Summarization, Translation, Q&A, Code Generation\\n        5.  Prominent Examples: GPT-4, LLaMA, Claude, Bard/Gemini\\n    E. **Prompt Engineering**\\n        1.  Definition: The Art and Science of Crafting Effective Inputs (Prompts) for AI Models\\n        2.  Goal: Eliciting Desired Outputs from Generative AI (Especially LLMs)\\n        3.  Key Skills: Understanding Model Behavior, Iteration, Creativity, Specificity, Contextualization\\n        4.  Importance: Maximizing AI Utility, Mitigating Bias, Enhancing Performance\\n\\n**III. The Relationship & Hierarchy: A Nested View**\\n    A. AI: The Overarching Discipline\\n    B. ML: The Primary Engine Driving Modern AI\\n    C. Generative AI: A Powerful Application Area within ML\\n    D. LLM Models: The Leading Edge of Generative AI for Text\\n    E. Prompt Engineering: The Human Interface for Interacting with and Directing GenAI/LLMs\\n\\n**IV. Detailed Comparisons & Key Distinctions**\\n    A. **Scope & Focus:**\\n        1.  AI vs. ML: General Intelligence vs. Learning from Data\\n        2.  ML vs. GenAI: General Learning vs. Creation of New Content\\n        3.  GenAI vs. LLM: Broad Generative Capabilities vs. Language-Specific Generation\\n    B. **Methodology & Output:**\\n        1.  AI: Diverse approaches, varied outputs (decisions, actions, predictions)\\n        2.  ML: Data-driven algorithms, outputs (predictions, classifications, clusters)\\n        3.  GenAI: Creation of novel data, outputs (images, text, audio, video)\\n        4.  LLM: Language processing, outputs (text, code, summaries, answers)\\n    C. **Role & Function:**\\n        1.  Models (ML, GenAI, LLM): The computational engines\\n        2.  Prompt Engineer: The human operator/designer interacting with the models\\n\\n**V. Understanding \"MCP\" in the Context of AI**\\n    A. **Clarification on \"MCP\":**\\n        1.  \"MCP\" is **not a standard or commonly recognized acronym** within the core fields of Artificial Intelligence, Machine Learning, Generative AI, or Large Language Models.\\n        2.  **Most Common Non-AI Interpretation:** Microsoft Certified Professional (a certification program for IT professionals). This is unrelated to AI paradigms.\\n    B. **Hypothetical Interpretations (If intended for AI):**\\n        1.  *Potential Misunderstanding/Typo:* Could it be a typo for another AI term (e.g., MDP - Markov Decision Process, MLP - Multi-Layer Perceptron, or a specific research project acronym)?\\n        2.  *Speculative \"Master Control Program\":* In some sci-fi contexts (e.g., Tron), \"MCP\" refers to a central, overarching AI. However, this is not a technical term used in current AI research or industry.\\n    C. **Conclusion on MCP:** Without further context, \"MCP\" does not fit within the established hierarchy or terminology of the other listed AI concepts. It\\'s likely either an unrelated term, a specific project acronym, or a misunderstanding.\\n\\n**VI. Interplay and Synergy**\\n    A. How Prompt Engineering Enhances LLM Performance\\n    B. The Role of LLMs as Building Blocks for Broader AI Applications\\n    C. The Future: Multi-modal GenAI and Advanced Human-AI Interaction\\n\\n**VII. Conclusion: A Dynamic and Interconnected Landscape**\\n    A. Recap of Key Distinctions\\n    B. The Importance of Precise Terminology\\n    C. The Continuous Evolution of AI and its Sub-fields\\n\\n---' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'} id='lc_run--80fae51c-2d48-4392-83f9-85544104817c-0' usage_metadata={'input_tokens': 26, 'output_tokens': 2855, 'total_tokens': 2881, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1584}}\n"
     ]
    }
   ],
   "source": [
    "message = model.invoke(\"can you create table of contents machine learning vs artificial intelligence vs generative ai vs llm model vs prompt engineer vs mcp?\")\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fb517d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ଆପଣଙ୍କ ଟିମ୍\\u200cମାନେ LangChain ଏବଂ Google Gemini ମଡେଲ୍ ସହିତ କିପରି କାମ କରୁଛନ୍ତି?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--c6f003cc-cdf5-4486-ab1f-0ba033733825-0', usage_metadata={'input_tokens': 23, 'output_tokens': 1112, 'total_tokens': 1135, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1073}})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into odia language\"),\n",
    "    HumanMessage(\"how are you teams working on langchain with google gemini model?\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37b940ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Here are a few ways to translate that, depending on the exact nuance you want:\\n\\n1.  **\"You all are doing great teamwork.\"** (Most direct and common)\\n2.  **\"You\\'re showing excellent teamwork.\"**\\n3.  **\"You\\'re working very well as a team.\"**\\n4.  **\"Great teamwork, everyone!\"** (More of an exclamation)', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--61585bdc-f98b-4c8b-a18a-5fefa4e2ba66-0', usage_metadata={'input_tokens': 18, 'output_tokens': 969, 'total_tokens': 987, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 883}})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from hindi into english language\"),\n",
    "    HumanMessage(\"बहुत अच्छा टीम वर्क कर रहे हो आप लोग\"), \n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3835e312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--44544b82-d3e9-49ff-90b3-9aa191591ace-0', usage_metadata={'input_tokens': 2, 'output_tokens': 37, 'total_tokens': 39, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 28}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Hello\")\n",
    "model.invoke([{\"role\": \"user\", \"content\": \"Hello\"}])\n",
    "model.invoke([HumanMessage(\"Hello\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5d9a90",
   "metadata": {},
   "source": [
    "# PROMPT TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf26e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"Translate the following from English into {language}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2082d8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following from English into odia', additional_kwargs={}, response_metadata={}), HumanMessage(content='how are you', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({\"language\": \"odia\", \"text\": \"how are you\"})\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7101b5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following from English into odia', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='how are you', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9aeb945a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "କେମିତି ଅଛନ୍ତି? (Kemiti achhanti?)\n",
      "\n",
      "You can also say:\n",
      "*   **ଆପଣ କେମିତି ଅଛନ୍ତି?** (Apana kemiti achhanti?) - This is more explicitly formal, adding \"Apana\" (you, formal).\n",
      "*   **କେମିତି ଅଛୁ?** (Kemiti achhu?) - This is informal, used with close friends, family, or someone younger.\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb48a75",
   "metadata": {},
   "source": [
    "## EMBEDDING WITH HUGGINGFACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf70a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-community 0.3.24 requires langchain<1.0.0,>=0.3.25, but you have langchain 1.0.4 which is incompatible.\n",
      "langchain-community 0.3.24 requires langchain-core<1.0.0,>=0.3.59, but you have langchain-core 1.0.3 which is incompatible.\n",
      "langchain-experimental 0.3.4 requires langchain-core<0.4.0,>=0.3.28, but you have langchain-core 1.0.3 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\Admin\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#pip install -qU  langchain langchain-huggingface sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7fd37483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c491b8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Admin\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fcc12fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is a test document.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50863efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = embeddings.embed_query(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be12df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.048951826989650726, -0.039862070232629776, -0.021562794223427773, 0.009908574633300304, -0.03810390084981918, 0.012684382498264313, 0.043494462966918945, 0.07183389365673065, 0.00974861066788435, -0.006987075321376324, 0.06352806091308594, -0.0303226038813591, 0.013839475810527802, 0.02580590732395649, -0.0011362765217199922, -0.014563619159162045, 0.04164034128189087, 0.036228347569704056, -0.026800835505127907, 0.025120751932263374, -0.02497860975563526, -0.00453327689319849, -0.02666715532541275, 0.0041007292456924915, -0.052048034965991974, -0.009930476546287537, -0.052065297961235046, 0.008992096409201622, -0.03830048441886902, -0.04405849799513817, -0.0042043994180858135, 0.07047972828149796, 0.005133942700922489, -0.07161542028188705, 1.6975313883449417e-06, -0.006047713570296764, -0.011076429858803749, 0.017513377591967583, -0.022299829870462418, 0.040954917669296265, 0.033790238201618195, 0.05665039271116257, -0.07114940881729126, 0.040976639837026596, -0.005906036123633385, -0.03297029435634613, -0.04011695832014084, 0.036905478686094284, 0.01044467743486166, 0.07072380930185318, 0.001900135655887425, -0.012058233842253685, 0.042883869260549545, -0.04503336176276207, 0.1064680740237236, -0.005948576610535383, -0.011797159910202026, 0.025893736630678177, 0.03904556483030319, -0.012367929331958294, 0.015381503850221634, -0.03134284168481827, -0.005073262378573418, -0.012316261418163776, -0.0024499509017914534, -0.02871890738606453, 0.05035025253891945, -0.05121351778507233, 0.03743273392319679, 0.008315305225551128, 0.11104641854763031, 0.008446868509054184, 0.001980606932193041, 0.06406252831220627, -0.02024790272116661, 0.056444231420755386, -0.012311534956097603, -0.036259423941373825, 0.028170736506581306, -0.025536684319376945, 0.023440444841980934, -0.03746704384684563, -0.035040948539972305, -0.026759231463074684, -0.02383614331483841, -0.003887732047587633, -0.03292238339781761, -0.030177872627973557, -0.0009559905156493187, 0.01800321415066719, 0.00290013593621552, -0.0347948782145977, -0.025890838354825974, 1.9747090846067294e-05, 0.07750262320041656, -0.01567281410098076, -0.05644114315509796, -0.1236935555934906, 0.07443564385175705, 0.014530841261148453, 0.041560098528862, -0.024861831218004227, -0.022402774542570114, 0.05856778845191002, -0.03246640786528587, 0.04108651727437973, 0.07885000854730606, 0.013646477833390236, 0.009003580547869205, 0.0983375608921051, 0.00842200592160225, 0.004841263871639967, -0.0381186343729496, -0.0025624260306358337, 0.04123970866203308, -0.024173444136977196, 0.02949548326432705, 0.004981836769729853, 0.007007945794612169, 0.07850863039493561, 0.0184720978140831, -0.021663673222064972, -0.025912171229720116, 0.009712676517665386, -0.025766652077436447, -0.059666674584150314, 0.00927385501563549, -0.02452506124973297, 0.02652047760784626, -0.04336711764335632, 0.02082270383834839, 0.02810269594192505, 0.03256068378686905, 0.029697533696889877, -0.012654099613428116, 0.027797119691967964, 0.039007194340229034, -0.03650738671422005, 0.0027240740600973368, -0.013410916551947594, 0.05861574783921242, 0.01977875828742981, 0.022310268133878708, 0.01511035393923521, -0.02565983682870865, 0.030828379094600677, 0.0026782613713294268, -0.015435019508004189, 0.01433168537914753, 0.02742570824921131, -0.0095685925334692, 0.027056129649281502, 0.0027635416481643915, 0.007311173714697361, 0.002585062524303794, -0.025712601840496063, 0.01893513835966587, -0.027686597779393196, -0.013943243771791458, -0.016881421208381653, 0.01597108133137226, -0.010773401707410812, 0.0003083116316702217, -0.025046268478035927, 0.014220349490642548, 0.03993040695786476, 0.011746738106012344, 0.0043335589580237865, -0.01856343448162079, -0.01730302721261978, -0.055866170674562454, -0.009961982257664204, -0.015036238357424736, 0.06309199333190918, -0.013529110699892044, 0.08178044855594635, 0.05368635803461075, -0.04181031137704849, -0.05746392905712128, 0.0548502616584301, -0.00637752516195178, -0.03353758528828621, -0.026076696813106537, 0.009464136324822903, -0.03805091977119446, 0.03635942563414574, -0.05167914927005768, -0.05559732764959335, 0.007560766767710447, -0.008203994482755661, -0.06730565428733826, 0.011553796008229256, 0.004411440808326006, -0.012197216041386127, 0.004297858104109764, 0.03841164708137512, -0.03532832860946655, -0.0017625167965888977, -0.007743257097899914, -0.013675774447619915, 0.029633453115820885, 0.013926811516284943, 0.08107918500900269, 0.06564438343048096, 0.0120347635820508, -0.022493265569210052, 0.041802484542131424, -0.05041944235563278, -0.0006258471985347569, 0.02937285415828228, 0.13278134167194366, 0.007509647868573666, -0.05461332947015762, -0.013333672657608986, -0.005744634661823511, -0.032623499631881714, 0.0006984243518672884, 0.014694890938699245, -0.0045336890034377575, 0.01410889346152544, 0.0018380265682935715, -0.06389147788286209, -0.02924233116209507, 0.0414627380669117, 0.005940991919487715, -0.11854619532823563, -0.01691160909831524, 0.02455238625407219, 0.04042097181081772, -0.020359203219413757, -0.0452011339366436, -0.003847535466775298, 0.024601267650723457, 0.08124666661024094, 0.012816247530281544, 0.014872700907289982, 0.02847786620259285, 0.003182684537023306, -0.02470957301557064, -0.088053859770298, -0.010611580684781075, 0.03667038306593895, 0.0029584302101284266, 0.04006437212228775, -0.04548341780900955, -0.03464098647236824, -0.0021476007532328367, -0.036805834621191025, 0.014849903993308544, -0.02041664905846119, -0.014622518792748451, -0.002651371993124485, -0.04491966962814331, -0.0013271160423755646, 0.011164998635649681, 0.018211379647254944, 0.011833473108708858, -0.0018385370494797826, -0.01894287019968033, -0.010859614238142967, 0.007092183455824852, -0.005436725914478302, -0.003482716390863061, -0.029499730095267296, 0.04902755096554756, 0.021220482885837555, -0.030143480747938156, -0.058468665927648544, -0.009746476076543331, -0.0049197073094546795, 0.02471461333334446, 0.004927187226712704, -0.020345162600278854, -0.01812058500945568, 0.016093790531158447, -0.05284429341554642, -0.045344918966293335, -0.011491427198052406, -0.02578490972518921, 0.016305966302752495, -0.030355360358953476, 0.039115678519010544, -0.026777416467666626, -0.005285922903567553, 0.005916598718613386, 0.04165315628051758, 0.005182791501283646, -0.017777305096387863, -0.04496513679623604, 0.06212930008769035, 0.042492300271987915, 0.013894294388592243, 0.0575622133910656, 0.0021977729629725218, -0.007051063235849142, -0.019615449011325836, -0.044110257178545, 0.049074459820985794, 0.01307867094874382, 0.057615913450717926, -0.019768711179494858, 0.019294727593660355, -0.021671265363693237, -0.019971366971731186, 0.025627100840210915, 0.07862606644630432, 0.06827373057603836, -0.0811096578836441, -0.00024307522107847035, -0.0026020973455160856, 0.021632660180330276, 0.018613753840327263, 0.0054062590934336185, 0.00860016793012619, -0.05482133850455284, -0.0016072302823886275, 0.019503245130181313, 0.011161875911056995, -0.034788377583026886, -0.029655925929546356, 0.009433010593056679, -0.00473009841516614, -0.009563562460243702, -0.02889718860387802, 0.018234733492136, -0.05373308062553406, 0.049921732395887375, 0.015174566768109798, -0.012218565680086613, -0.03936775401234627, -0.017829082906246185, -0.012593233026564121, -0.035229817032814026, 0.015881191939115524, 0.02720734104514122, 0.032223641872406006, -0.029802728444337845, -0.013283099979162216, -0.0173228457570076, -0.007744431961327791, -0.029652714729309082, -0.0039690276607871056, -0.0002516100066713989, -0.016964038833975792, 0.060570988804101944, 0.025926070287823677, -0.016243839636445045, 0.04880784824490547, -0.07821014523506165, 0.007661573123186827, 0.024504108354449272, 0.062189701944589615, -0.02423696592450142, -0.027578409761190414, -0.016785090789198875, 0.011569621972739697, -0.0011424425756558776, -0.03219850733876228, 0.016834769397974014, -0.06426291912794113, -0.0450122132897377, -0.018889373168349266, 0.003373071551322937, 0.0832737609744072, -0.008741769008338451, -0.01285364106297493, -0.02219424955546856, -0.013637755066156387, -0.01144914235919714, 0.005819301120936871, -0.046268168836832047, 0.010632075369358063, 0.01296911295503378, 0.03821879252791405, -0.002291250042617321, 0.015075694769620895, 0.001911032828502357, -0.03767937049269676, -0.07249950617551804, -0.008411632850766182, 0.03696969151496887, -0.01755855232477188, 0.06880619376897812, 0.021453989669680595, 0.015587902627885342, 0.05685378611087799, 0.029211049899458885, 0.00810097623616457, 0.025702333077788353, 0.017727075144648552, 0.01234455592930317, -0.006845060735940933, -0.028087647631764412, 0.014013223350048065, 0.013951882719993591, 0.02480284869670868, 0.03259958326816559, -0.012523738667368889, -0.004361097235232592, -0.009915871545672417, 0.002845131792128086, -0.016797875985503197, -0.030143288895487785, 0.01617049239575863, 0.05340949818491936, -0.02838180772960186, 0.017854884266853333, 0.010577572509646416, -0.021634191274642944, -0.01610075682401657, 0.011083360761404037, -0.06762567907571793, 0.05928746610879898, -0.010530338622629642, 0.012286340817809105, -0.00391062768176198, 0.008294163271784782, 0.035265274345874786, -0.012232188135385513, -0.020732633769512177, -0.031160028651356697, 0.010900896973907948, -0.0004538309876807034, -0.036872748285532, -0.03128848597407341, -0.02624337375164032, 0.008714060299098492, -0.0067697311751544476, -0.0008914743084460497, 0.01317583303898573, -0.017217257991433144, -0.040858034044504166, -0.04406452178955078, 0.04710858687758446, -0.0733436718583107, 0.010102053172886372, -0.06431175768375397, -0.031158743426203728, 0.07408104836940765, -0.06896299123764038, -0.02388720028102398, 0.015100259333848953, 0.0981069803237915, 7.636288501089439e-05, -0.06588448584079742, -0.018785007297992706, -0.04284920170903206, -0.0151737742125988, 0.032768260687589645, 0.034769296646118164, 0.01945466734468937, -0.035235077142715454, -0.04279060661792755, -0.02763875387609005, 0.052593354135751724, -0.01369862724095583, -0.023015756160020828, 0.002235575346276164, -0.02413930930197239, 0.019655805081129074, -0.050136882811784744, 0.039895690977573395, -0.06709931045770645, -0.01964224874973297, -0.006665438413619995, -0.0030730904545634985, -0.055939797312021255, -0.04594258964061737, -0.007018112577497959, -0.009679985232651234, -0.09004715830087662, -0.004296561237424612, -0.026762695983052254, 0.013158767484128475, -0.008696428500115871, -0.0239962600171566, -0.0795711949467659, 0.04904184117913246, -0.026166893541812897, -0.02395893633365631, 0.04107879847288132, -0.03358324617147446, 0.01802295818924904, -0.014274273999035358, -0.01139078475534916, 0.055004388093948364, -0.0033767675049602985, -0.004523253999650478, 0.04888889193534851, -0.030169034376740456, -0.024715891107916832, -0.01328546367585659, 0.004581518471240997, 0.05256754532456398, -0.04146482050418854, 0.035698700696229935, 0.03172890096902847, 0.02212763950228691, 0.011092050932347775, -0.026061933487653732, 0.0054838391952216625, -0.018752364441752434, -0.0340702123939991, -0.05245077982544899, -0.07468506693840027, 0.019256427884101868, 0.010930676944553852, 0.06089542806148529, -0.0028150994330644608, 0.03415965288877487, 0.012567962519824505, -0.006941088940948248, 0.019576193764805794, 0.016067633405327797, -0.03510173037648201, 0.02143552154302597, -0.07849914580583572, -0.037819910794496536, -0.03217640519142151, -0.035520218312740326, 0.020244648680090904, 5.566826439462602e-05, 0.010879823006689548, -0.02721722051501274, -0.0176896620541811, -0.000967161962762475, 0.04210837185382843, 0.018853824585676193, -0.03063838928937912, 0.028566712513566017, 0.040422555059194565, -0.0468258298933506, -0.08438970148563385, 0.05134314298629761, -0.05905357375741005, 0.050269003957509995, 0.06808411329984665, 0.023491233587265015, 0.007946459576487541, -0.05953718349337578, 0.04055814817547798, -0.04486170411109924, 0.08326677232980728, 0.01574946939945221, 0.0030637243762612343, 0.01064089871942997, -0.01109243929386139, 0.04247095435857773, -0.016391316428780556, -0.03567042574286461, 0.029383791610598564, 0.04604053869843483, 0.002785029821097851, 0.020644592121243477, 0.025102347135543823, -5.9334131629250856e-33, -0.024000996723771095, -0.018269728869199753, -0.011575206182897091, 0.032587312161922455, 0.06249982863664627, 0.016683217138051987, -0.018460752442479134, -0.006273373961448669, -0.011595289222896099, -0.011493300087749958, -0.02407977543771267, -0.00988786667585373, 0.047138068825006485, -0.002340869512408972, -0.018301764503121376, 0.02934248000383377, 0.0368524007499218, -0.02523815631866455, -0.030984599143266678, -0.038825735449790955, -0.06142910569906235, -0.04164126515388489, 0.052531495690345764, 0.00917152501642704, 0.007774265017360449, -0.005371580366045237, -0.012983100488781929, -0.06309034675359726, -0.03462984412908554, 0.006059092469513416, 0.017732180655002594, -0.041676413267850876, 0.0018815553048625588, 0.018784426152706146, 0.006285404320806265, 0.0927204117178917, -0.05162035673856735, -0.04394694045186043, 0.004336989484727383, 0.029026953503489494, -0.03314035385847092, 0.01156482845544815, -0.008395391516387463, -0.05503441393375397, 0.014819944277405739, -0.0274847149848938, -0.010173115879297256, 0.020949386060237885, -0.04530283808708191, -0.0006497652502730489, -0.06503000855445862, 0.018690748140215874, -0.003195947501808405, 0.0767844021320343, 0.020966345444321632, 0.057918794453144073, 0.0018411367200314999, -0.11284707486629486, -0.03336092829704285, -0.013443447649478912, 0.05365249142050743, 0.007487385533750057, 0.027319597080349922, -0.04490711912512779, 0.002949978457763791, 0.011659198440611362, -0.05776110664010048, 0.11195847392082214, 0.0317496694624424, -0.04268903285264969, 0.07711005955934525, 0.015468795783817768, 0.02213199809193611, 0.06470637023448944, -0.00431336322799325, 0.0008150776266120374, 0.03645959123969078, 0.05525561794638634, 0.0450737290084362, 0.027272099629044533, 0.02792809158563614, -0.03785426914691925, -0.04701896384358406, -0.01928274892270565, -0.03578218072652817, -0.034927256405353546, -0.02103452943265438, -0.03682974353432655, 0.03234702721238136, 0.0006681513623334467, 0.03450661152601242, 0.033645838499069214, -0.014016315340995789, -0.0038343416526913643, -0.006102891638875008, 0.04318404197692871, -0.007634124252945185, 0.020867638289928436, -0.046900685876607895, -0.06625127047300339, -0.02287513017654419, -0.02231927029788494, 0.046614013612270355, 0.016954058781266212, 0.03459366410970688, -0.01022699661552906, 0.011531330645084381, -0.02231653407216072, -0.08706125617027283, -0.009941231459379196, 0.019363269209861755, 0.019819751381874084, 0.04798024147748947, -0.026108864694833755, 0.0018011948559433222, 0.027875181287527084, 0.0424293614923954, -0.0051893130876123905, -0.019823366776108742, -0.09299398958683014, -0.007746369112282991, 0.02032330073416233, 0.010362648405134678, -0.004718981217592955, 0.017852555960416794, -0.0095508499071002, 0.010867671109735966, 0.0201142318546772, 0.041950494050979614, 0.017006520181894302, 0.025575025007128716, 0.041161131113767624, 2.1937933070148574e-07, 0.046683795750141144, 0.05986520275473595, -0.0017903933767229319, 0.04450717940926552, 0.020549623295664787, -0.06274867802858353, -0.02741178683936596, 0.03065030835568905, 0.012108501978218555, 0.02638188935816288, 0.02348732203245163, -0.05434541031718254, 0.04075966775417328, 0.06828773766756058, -0.04877595603466034, 0.006711374036967754, 0.0033980763982981443, -0.02613583765923977, -0.0026950580067932606, -0.020351724699139595, 0.03207649663090706, -0.007281239610165358, 0.004395944532006979, -0.013535424135625362, -0.0012210487620905042, -0.01718945987522602, -0.006443811114877462, -0.027577238157391548, -0.01881597191095352, -0.022696906700730324, -0.0016465553781017661, -0.015567243099212646, 0.030649036169052124, 0.08345631510019302, -0.05150885134935379, -0.006219938397407532, 0.015209896489977837, 0.07055509835481644, 0.008788797073066235, 0.052301231771707535, 0.020923219621181488, -0.07696112245321274, -0.007996562868356705, -0.009195590391755104, 0.034557487815618515, 0.06591441482305527, 0.06452193856239319, -0.029098767787218094, -0.06825070083141327, -0.05451348423957825, 0.026412902399897575, -0.00866518821567297, 0.02500324323773384, 0.005197408143430948, 0.011412927880883217, -0.061457447707653046, -0.008846844546496868, 0.04972579702734947, 0.03543199598789215, 0.03754955902695656, -0.04157828167080879, 0.011635974049568176, 0.019122794270515442, 0.019156450405716896, 0.02018989622592926, -0.023114105686545372, 0.0006884059403091669, 1.7672967521550278e-34, -0.0034137240145355463, -0.029410570859909058, -0.0033265079837292433, -0.022781070321798325, -0.007766885682940483, -0.017573997378349304, 0.10172579437494278, 0.03783344849944115, -0.01155010424554348, -0.05878182873129845, -0.011569155380129814]\n"
     ]
    }
   ],
   "source": [
    "print(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c5898ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.048951826989650726, -0.039862070232629776, -0.021562794223427773]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fc50e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2eab37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
